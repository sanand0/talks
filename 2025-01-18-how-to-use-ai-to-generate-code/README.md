## How to use AI to generate code?

<iframe src="https://www.youtube.com/embed/pbRFDUGby3o" title="YouTube video" loading="lazy" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen width="600" height="400"></iframe>

[The Hindu Webinar on How to use AI to generate code? 18 Jan 2025](https://www.thehindu.com/sci-tech/technology/the-hindu-to-host-webinar-on-the-use-of-artificial-intelligence-in-education/article68769905.ece)

**Srini:** Hello everyone, good evening and welcome to The Hindu’s webinar on the topic: **How to use AI to generate code**. We have a distinguished panel with us. Let me introduce them.

We have **Professor Arun K. Tangirala**, who is a professor at the Department of Chemical Engineering, IIT Tirupati, and a professor on lien at the Department of Data Science and AI, Wadhwani School of Data Science and AI, IIT Madras. He is a Dean of Competency Development and Outreach at IIT Tirupati. His research focuses on fundamental problems in systems and control theory, data science, and AI, and their use in process engineering, fault detection, transportation, climate, biological processes, and education. Dr. Tangirala also leads the **Swayam Prabha project** as its chief coordinator. The project is a high-impact, large-scale outreach educational initiative of the Ministry of Education, Government of India. Welcome, Dr. Arun.

Our other panelist, **Anand**, is a co-founder of **Gramener**, a data science company. He leads a team that tells visual stories from data. He is recognized as one of India's **top 10 data scientists** and is also a regular TEDx speaker. Anand is a gold medalist from IIM Bangalore and an alumnus of IIT Madras, London Business School, IBM, Infosys Consulting, Lehman Brothers, and BCG. I can also personally vouch for Anand as a trainer for scores of data journalists in India in the past decade—I am one among them. Anand's work has acted as a catalyst for the flourishing of data journalism in India, including at The Hindu. He has helped us with a number of projects and guided us regarding the use of numerous tools and applications. He is also the world's first officially designated **"LLM Psychologist."** We will get to what exactly that means later. Welcome, Anand. Welcome to both of you to the show.

Before we listen to them, I just wanted to elaborate on the topic a bit. We know that GenAI has revolutionized the field of information technology. The advent of GenAI has meant that information dissemination has graduated from the use of search engines—that pointed to websites and used to organize the gates to the vast information that is the internet—to organizing information in the form of **answers to prompts and questions**. It has provided a key to produce meaningful information out of data using natural language prompts.

We have known and discussed the issues with information created by GenAI: the issue of hallucination, misleading conclusions due to skewed and biased data that the models are trained on, among others. But there is a much bigger and beneficial flip side to the use of GenAI. This regards the use of prompts to **create code and programs**, including for people who are not strongly trained in programming or coding. This utility is, in my opinion as a journalist, **transformational**. I can attest to GenAI’s coding ability helping us in The Hindu’s data and visual journalism. We were able to create visual stories, mine and scrape data, and organize and visualize data in ways that were not possible for us before the advent of AI to do on our own.

Clearly, the potential of using GenAI to write structured code raises the possibility of revolutionizing the coding industry, with tasks becoming far easier for coders and programmers. But it also comes with fresh risks. How does this affect white-collar workers, coders in particular, and their jobs? How do we make use of this profound facility? What kind of training and skilling is required to hone graduates to utilize the power of GenAI? How do we mitigate the deleterious impact on white-collar jobs and instead use this as an opportunity? That will be the subject of the discussion with our panelists.

I will go to Professor Arun first. He has a presentation. We will start off with that.

---

### Presentation by Dr. Arun K. Tangirala

**Dr. Arun:** I completely agree that AI has taken the world by storm and has been disruptive in many ways. It has begun to revolutionize every sector, including, of course, education and learning. There are many aspects of learning and education that AI has been impacting significantly and will continue to do so because the AI technology itself is evolving. Most of us really do not know the potential of these tools; therefore, we will have to spend some time figuring out how to use them best, apart from handling other issues such as accountability, ethics, and so on.

I can tell you that **AI has been very impactful in bringing about personalized education, large-scale learning, enhancing EdTech solutions, and of course, code generation and evaluation.** Apart from that, you have AI impacting analytics. AI has generated enormous resources and continues to generate them.

One point I want to make, which we discussed in the last webinar with The Hindu, is that we should not be thinking of these tools merely as "tools." **I think they have a human nature to them.** Both Anand and I agree—in fact, Anand cannot disagree because he calls himself an **LLM Psychologist**. Typically, we talk of psychologists for human beings or living beings. Therefore, you may call an LLM (Large Language Model) a "Large Living Model." It is important to develop that perspective because once you start treating it as a "trained human," you know that the tool comes with its own pros and cons.

AI has had multi-dimensional utility. Not all of these are currently explored, but AI is useful whether it is for a student or a teacher. Both continue to benefit from the knowledge enrichment that LLMs bring and the personalized learning that I can set up as a teacher. In fact, there are many ecosystems starting to bloom, like "School AI," which sets up an entire ecosystem involving not just LLMs, but chatbots. It’s like I hire an "AI Teaching Assistant," customize that TA, and ask that chatbot to answer questions the students may have. I can keep track of the questions, generate assessments, and so on. There are a lot of things that can be done which you couldn't think of earlier. But all of this has to be done in an ethical way, and you must have the infrastructure. Finally, you will have to bring about curriculum changes to be able to use AI for all these things.

The focus of today's session is **AI for coding**. I put coding on the teacher's side as well as the student's side because I use AI tools for bringing up codes, and I use those codes to teach.

Let's pause for a moment and ask: **How do humans learn to code?** The answer is by training in a sequential order of concepts through courses. One of the first things we are taught is **computational thinking**. This has really picked up momentum even at the school level. Even though you are not doing computation, you can read it as "computer-like thinking." How does a computer think? There is logic, there is a sequence.

Then you have **programming**. I want to highlight this: **Programming is both a science and an art.** Art comes from experience, and science is taught in the courses. You learn languages such as C, Python, R, and we are taught the art of writing programs—flowcharts, modules, interconnections. For advanced learners, it could be about understanding compilers and interpreters. Then the learners get to write, practice codes starting from simple ones to big projects. They evaluate, compare different codes, debug, and perform "ethical hacking" of codes.

If you are really passionate, you join the coding community. I know for sure Anand was coding way before he joined me as my classmate at IIT Madras. So, there are people who are very passionate. When you think of coding, you can code for data science, gaming, software development, building models. The end-use really determines what you code and what tools you will use.

**Contrast this with how AI learns to code.** Unlike humans, AI models learn to code through tons of examples. We use Natural Language Processing (NLP) methods combined with heavy-duty neural networks and deep learning algorithms. The result is Large Language Models (LLMs) like ChatGPT, Claude, Gemini, etc. Models are fed with thousands of code datasets and trained with learning algorithms.

The main feature of these trained models is that the user can prompt—can write a simple text instruction—to generate code. That is where **prompt engineering** comes in. This is completely a revolution. We used to do that with humans; now we are doing this with AI models. You could tell the coder in your office, "I would like you to write a code for doing this," and now you are telling the model.

AI tools for coding are also equipped with the ability to **translate code from one language to the other** (e.g., R to Python, COBOL to Java).

Using GenAI to write code has several benefits, but not without issues and challenges. I have a list of **FBQs (Few Burning Questions)**:

**1. Is GenAI-based coding the same as Low-Coding or No-Coding?**
Not at all. Low-coding or no-coding has to do with drag-and-drop, pre-built templates, and libraries where you don't have to write the code. Whereas **GenAI-based coding is completely prompt-based.** The better your prompt is, the more effective your code is.

**2. I am a newbie to coding. Could I straight away start using GenAI? Will I learn how to code if I use these tools?**
Here is where you have to think whether you are going to be a **learner** or a **one-time user**. If you are a one-time user, even a learner could straight away start using it. But what you do _after_ determines what your aim is. You can certainly start using GenAI tools, but you wouldn't know whether the code is correct or efficient. **It is always good to go through a basic programming course in that language so that, at least when you look at the "product" the shopkeeper is giving you, you should know whether it is of good quality or not.**

By looking at the code, you can also improve your coding. There are several benefits, but you have to use this with human intervention under the guidance of a trainer.

**What are the prime benefits and risks?**

- **Benefits:** Improve productivity. I don't need to spend a lot of time learning _how_ to code; I would rather learn the _concepts_ and then use these tools. I save time and focus on my expertise. It gives accessibility—people who do not know coding can use this.
- **Risks:** Trustworthiness. Is the code correct? Is it going to crash your computer? One of the biggest risks is **security, over-reliance, and bias.** Your tool can be hacked, or your code can be inserted with things you wouldn't know. You need a very secure platform.

**What is the role of programmers in this emerging era?**
Some people believe my job as a programmer is going to go away. Yes, that is true **if you stick to only writing codes.** One has to upskill oneself and say, "Now I will learn how to **evaluate** a code. I will be an expert in **comparing** two codes and **nudging** these tools to write better codes." I still go through programming courses, but not to necessarily write codes, but to make the codes coming from AI tools better and more reliable.

**Demo using Perplexity:**
I’ll use Perplexity. Since I come from a data science background, I will ask Perplexity to **"write a code in R for developing a linear regression model."** By default, tools assume you are interested in Python, but I want to use R.

It installs the packages. One of the good things about any tool is it should be able to **explain** what it is doing. It says "Load your data." But if you do not know any of these packages, you will just take it and keep going. That's not recommended. It calculates coefficients, fits a linear regression model, and visualizes the results.

It is using `lm`, which is a very standard routine in R for linear regression.

Now, I will ask Perplexity: **"Write this code from scratch _without_ using `lm`."**
It says, "Certainly." Now it actually defines a function. **It also gives you the math behind it, which is great.** As a teacher, I find this very useful to teach certain audiences. I can start from the code and understand each line. It uses the original formula to calculate coefficients.

I can ask: **"What is the benefit of using `lm` versus writing from scratch?"**
It gives the answer: The `lm` function is easy to use, has built-in diagnostics, is robust, and has comprehensive functionality. Writing from scratch enhances understanding—it says, "underscores mechanics."

**To conclude:**
As we adopt tools, we will have to incorporate changes in other components of the educational system. Institutes must come up with policies. Self-learning and peer learning have to be encouraged because you have to join coding communities. **Libraries also have to pick up—they can become repositories of algorithms or best AI practices for coding.**

With AI-based coding, we will all have to redefine outcomes and our roles while integrating these tools. We have to develop competence, not just be competitive. Ultimately, we have to be human, scientific, and artistic.

---

**Srini:** Thank you, Dr. Arun, for the lucid explanation. Anand, you are a practitioner and a coder. Nothing can emphasize the import of GenAI and its ability to code than seeing it in action. Can you provide us with more examples? Also, we would love to understand the meaning of the term **"Prompt Engineering"** and while you are at it, can you elaborate on **"LLM Psychologist"**?

**Anand:** **Prompt engineering is basically learning how to talk to LLMs.** And this is not obvious. What research is showing is that if you tell an LLM "Give me a good answer, my life depends on it," the answer tends to be right more often. **If you say "I will tip you $10,000," it gives a better answer.** This falls under a category called **"Emotional Prompts."** The fact that an LLM would be prone to emotional blackmail is not obvious! That is the kind of thing people are discovering through prompt engineering.

Part of why I call myself an LLM Psychologist is because I am poking around LLMs, asking them questions, and trying to figure out what works and what doesn't.

We’ve learned a few things about prompt engineering that seem to work across models:

1.  **Chain of Thought:** Ask an LLM to "think step-by-step." Write whatever you want, and at the end say "Think step-by-step." It does better.
2.  **Persona:** "You are an expert Python programmer" or "You are an expert psychologist." It tends to do better.
3.  **Few-Shot Prompting:** Giving examples makes a huge difference. Instead of asking it to categorize something as high/medium/low, split it into a series of Yes/No questions.

### Live Demo by Anand S

**Anand:** Let me walk through a few examples of applying what Arun showed in terms of generating code. I'm going to take a slightly different scenario. Rather than copy-pasting code, I want the program to be built and deployed automatically.

One of the first problems I have is clients coming to me with vague requirements. For example, Srini was talking about an election dashboard. We want an election dashboard; it should look beautiful, but we don't know what it should have.

**Prompt:** _"Create an election dashboard for Indian national elections. It should look really beautiful and be interactive and media should love it. Give me a design for this that I can build on top of, but make it like a demo that looks like it's real so that I can show it to the client. Put in names of Parties A, B, C and all of that stuff."_

You'll notice I am writing like I am talking. That is okay. In this case, it uses an approach called a **Canvas** approach. There is something on the right-hand side which it can edit. It’s writing some fairly detailed code using React and Recharts.

The beauty of this is I can click on "Publish" and copy the link. It is actually available as a dashboard that you can see.

**Iterative Prompting:**
I have some problems with this. I want it to fit on one screen, and there is no animation. So rather than try and change the code myself, I will tell it:
**Prompt:** _"I want it to fit in one screen. Add animation. Things should bounce around because clients like that sort of thing."_

Now what it is going to do is **revise the code that it wrote earlier**. It’s cooking up data as well—BJP won so many seats, Congress won so many seats. It's doing a reasonably realistic job. Not only do I not have to imagine the dashboard, I don't have to imagine the data structure.

**Srini:** Thank you for using a live example. With respect to ethics, we know that the code GenAI generates is derived from its learning based on open-source databases. What is the impact of this on the ownership and license of the generated code?

**Dr. Arun:** That is actually still being debated. But the broad understanding is: if I am a developer giving a code generated by AI, and if the use of that code results in harm, the developer can be held responsible. There seems to be some consensus on that. We don't have regulations yet in any part of the world.

What is being asked is to **declare**. In one of the leading universities in Australia, they are asking students to not only declare _which_ tool they used but also **all the prompts that have been used**. This ensures transparency.

**Srini:** A viewer, Krishnamurthy Ganesan, asks: _"As a non-programmer interested in stock trading, how can I leverage AI-generated code to analyze market trends? Can you recommend platforms?"_

**Anand:** Actually, rather than me taking this, let's do one thing. Let's ask ChatGPT.

_(Anand activates ChatGPT Voice Mode)_

**Anand (to ChatGPT):** How can a person who is not a programmer create an application that helps them trade better on the stock market?

**ChatGPT Voice:** Good question, Anand. AI at its core is like a really smart librarian—great at finding connections in what's already been written. True innovation, though, often involves asking new questions or thinking outside the patterns. That said, AI can still spark innovation by combining ideas in ways humans might not have thought of. For example, it might suggest a Python script that blends geospatial data with customer sentiment—something no one had asked for but suddenly feels groundbreaking. But here's the twist: **AI needs humans to guide it. It's like having a Swiss Army knife; it's not innovative by itself, but in the right hands, it's a game-changer.** What do you think, Anand? Does innovation come more from AI or the human wielding it?

**Anand:** What do you guys think?

**Dr. Arun:** AI is leading to a combination of human intervention and automation. You have new tools, so one has to master these tools. Better to realign than to resign.

**Srini:** I noticed when you used prompts, you used very precise English. I've noticed if I use very precise, clear language without grammatical mistakes, it generates code more accurately. Is there truth to that?

**Anand:** LLMs are excellent at **mimicking style**. If you mimic poor-quality English, it assumes that it should give a poor-quality response. So, it is actually trying to follow what you are doing.

Does that mean we need to learn better English? Maybe. But here is the thing: we can do this very easily with a **two-step solution**. Internally in our organization, we found that people give terrible prompts. One person's entire prompt was just "Education Dashboard."

So we made it a two-step process:

1.  **Step 1:** One LLM takes the user's rough prompt and creates a **full-fledged specification** that is enough for a software developer.
2.  **Step 2:** Pass that specification to the model to generate the code. The quality dramatically increases.

**Srini:** A question from Dr. Gerald Inico: _"Integration of AI tools disrupted learners' creativity. What are the strategies to overcome challenges, and since AI relies on past data, how can it drive true innovation?"_

**Dr. Arun:** The skill set required of a human being has changed over centuries. Assuming that the _same type_ of skills/creativity is required would stall our growth. **Example: The Calculator.** When calculators came in, people had great calculation skills. You can't ask, "Did the calculator kill creativity?" The law of nature is that some other skill is required.

Innovation and creativity are not going away. You have to come up with _new_ innovations using these tools creatively. Even if I give you a calculator, there are students who don't know how to use it. The same will happen with these tools.

**Anand:** I'll answer the second part. Since AI relies on past data, how can it drive innovation?
One: **Experts benefit more than novice developers.**
Two: **Don't memorize syntax. Learn data structures, algorithms, and design patterns.** These work across languages.
Three: **Practice using AI for coding.** Start with debugging. New code generation works better than updating code.
Four: **Do not write documentation.** AI does a fantastic job; save your time.
Five: **Test Case Generation.** You hate writing test cases? Delegate that to an LLM.

**Review code by comparing multiple solutions.** Give it to Claude, Gemini, ChatGPT. Compare the outputs. Ask Gemini to critique Claude's code.

**Ask it to explain itself.** Why did you choose this library?

**Look for "Code Smells."** As you gain experience, you'll look at code and say, "This feels weird." Poke in those areas.

**Dr. Arun:** I just want to add: **Please don't ignore domain knowledge.** If you have no idea how stock markets work, whether the stock market will crash or not, your investment is likely to crash. Better to have domain knowledge so you understand what the code is doing.

**Anand:** Let me talk about what I see on the job side. The World Economic Forum released a projection of the fastest growing and declining jobs. **Number 4 on the fastest-growing jobs is Software and Application Developers.** There is an interesting economic paradox: **When the cost of something goes down, the demand goes up.** A programmer who could write 100 lines of code can now write 300 lines of better quality.

Are new skills coming in? Not _yet_. We are still at the stage where we don't know what we need. Once people figure that out, things will scale.

**Srini:** How are you deploying these tools? Is it within the flow?

**Anand:** Three kinds of applications:

1.  **Existing applications:** e.g., a publishing system where AI helps identify alignment.
2.  **LLM-only applications:** The _sole purpose_ is to do something not possible earlier. E.g., analyzing customer survey topics automatically.
3.  **Agentic Applications:** Starting to do things in the real world. E.g., calling a restaurant to make a reservation (like OpenAI showed).

**Dr. Arun:** I think we will end here. Thank you very much.

**Srini:** Thank you, Dr. Arun and Anand. As you pointed out, this is an evolving area. New futuristic projects are possible. Unanswered questions regarding data protection remain. But for non-programmers, there is no shortcut to using GenAI without understanding the basics. Go through your basic programming knowledge, and that will keep you in good stead. Thank you, everyone.

---
