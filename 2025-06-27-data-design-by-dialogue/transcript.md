# Data Design by Dialogue Transcript

<!--

Generated by Gemini 2.5 Flash (thinking) on https://ai.dev/ (since the Gemini app is rubbish.)

Uploads:
  - audio.mp3 via `ffmpeg -i video.mkv -b:a 16k -ac 1 -application voip -vbr on -compression_level 10 audio.mp3`
  - README.md -- which _dramatically_ improves context

Prompt:
Transcribe this talk audio.mp3 which was delivered with the slides README.md. Make only MINIMAL modifications to correct speech. Drop "um", "uh", etc. to smoothen the speech. Break it into logical paragraphs, beginning each paragraph with a timestamp. Use Markdown formatting, emphasizing with emphasis or bold for key points. For audience questions, prefix with "Question: ..." and answers with "Answer: ...".

-->

[00:05](https://youtu.be/hPH5_ulHtno?t=00m05s) We're going to be creating charts just by talking to an LLM. You can find the slides, as well as the prompt, using that QR code. I'm going to specifically take the WhatsApp group that the VizChitra team has been using. This is the core team. They added me in the early days assuming that I would be an active participant and you will soon see exactly how active I was. Now, problem number one is WhatsApp doesn't allow a data export. So how do we get that data? Let's ask ChatGPT.

[00:47](https://youtu.be/hPH5_ulHtno?t=00m47s) See, what I find is that LLMs can help in **every step of the value chain**. Maybe not today, maybe not completely, but they are improving faster than we can imagine. Two years ago, they had the level of intelligence of a grade eight student. Today they have the level of intelligence of roughly a postgraduate. So the pace at which it's going, we will soon have a very strong intelligence. And there is also a jagged edge. In some areas they are **extremely capable**, in some areas they are far less capable. We don't yet have an intuition of how well they do in different areas, so experimentation becomes important.

[01:24](https://youtu.be/hPH5_ulHtno?t=01m24s) But, personally, I think, after open data, which let everyone have access to fairly solid fuel for insights, this, that is the use of LLMs to make sense out of data, might be the single biggest democratization of this. And what I'm going to do is show you some of the ways in which that might be possible. These are experiments that you should try, improve on, explore. We are all exploring, really.

[01:59](https://youtu.be/hPH5_ulHtno?t=01m59s) So, one of the things that I'd love to do is ask ChatGPT. Let's, in fact, just literally ask it right now. I want to scrape data from a WhatsApp group and I just want to do that by pasting JavaScript into the DevTools console. Now, you write me code for that. Give me the code that I can paste into the console, which will copy any HTML or whatever else is required from that WhatsApp web page. Make sure that the text is not too long, trim it as required, and put it into the clipboard. I will paste it here, you can then write the code to scrape all the useful information in each message and give it to me as an **array of JSON objects**.

[02:46](https://youtu.be/hPH5_ulHtno?t=02m46s) Let's give it that instruction. I find it a whole lot easier to talk. I find that when I talk, I am a lot more verbose. When I type, it's hard. The other advantage that I have is that I can talk while walking, which, typing while walking is a little harder, doable, but harder. I also can talk while cycling, which is so far been close to impossible when it comes to typing.

[03:12](https://youtu.be/hPH5_ulHtno?t=03m12s) Now, the model that I'm using matters. I am on the $20 ChatGPT account. There is also a $200 version and there is a free version. In the $20 version, you get reasonably liberal access to the close to the best models. On the $200 version, you get liberal access to the best models. And $20 is, in my opinion, worth it, far more. It's not that much compared to, let's say, it's probably your Netflix plus Prime Video plus whatever spend in a month. And it is incredibly worth it.

[03:46](https://youtu.be/hPH5_ulHtno?t=03m46s) So, what this has told me is just take this piece and put it into the WhatsApp console. And which if I figure out how to do. Let's do this and paste it. It says, "Not allowed error, failed to execute right text on the clipboard." And this sort of thing happens. This is very common. Do not worry about stuff that doesn't work. You have an assistant that's going to help you. So, I got this error. "Just fix it."

(Laughter)

[04:31](https://youtu.be/hPH5_ulHtno?t=04m31s) Now, seriously, I actually don't know why you're laughing, because **this is how it's done**. How else would we do it? A lot of people at this point feel a compulsion to think, to try and solve the problem that problem solving is an important skill. Yes, maybe problem solving is an important skill. But **what problem to solve** and knowing the difference between which ones you want to solve and which ones you want to give to an LLM is also an important skill. Reminds me of some quote, Alcoholics Anonymous or something.

[05:09](https://youtu.be/hPH5_ulHtno?t=05m09s) But anyway. Now it's saying "copied via exact command". Did it really copy something? Let's find out. I'm going to paste here. It did not. So, it's still saying "copy via exact command, blah blah blah". And I'm going to tell it, "No, I still got this error. I still get this error."

[05:30](https://youtu.be/hPH5_ulHtno?t=05m30s) Now, this is technique number one, which is **tell it, fix it**. Technique number two is **don't confuse it, just ask it again**. The beauty of LLMs is they can go wrong, but they go wrong in reasonably independent ways. So, if I take the same thing and give it again, it will probably give me a different result. Now some people worry about this. They say, "Oh, but an LLM is not like a program where it's reliable." Brilliant. Then if it makes a mistake once, the next time it might not make that mistake. And if it makes a mistake once and you pass it to itself and say, "Check what errors you found," it'll probably not make the same mistake again, it'll make a different kind of mistake. And therefore you can trust an LLM a little more to verify itself. And this one worked. I think, because it's saying it's worked. So let's find out. Paste it and it's got some stuff. Great.

[06:19](https://youtu.be/hPH5_ulHtno?t=06m19s) So now that I have some HTML, that is, I know roughly what the text of the WhatsApp page looks like, we can have the go to the next step, but before that, here are some of the things that I would like to share as my learnings. **LLMs make mistakes**. And the important thing is that LLMs make mistakes kind of like humans. You ask a human to process a long document, they will miss out stuff. Code makes fewer mistakes and different kinds of mistakes. So, I usually have LLMs **write code and run the code**. Code is a language, LLMs are language models, literally. So, they actually tend to be pretty good at this. And because of this, **anyone can code**. You'll notice what I said there, took a certain amount of expertise. I'm not saying that expertise is not required. But it's something that enables anyone to write programs in English. And that expertise that I'm talking about is actually now easier to develop.

[07:16](https://youtu.be/hPH5_ulHtno?t=07m16s) So, with this, let's do the following. I am going to say, I'm going to go back here and literally just paste the HTML that I got and tell it, "Give me the." I think I already told it, "You can write the code to scrape all the useful information." Yeah, I'll just say the same thing again, "Here is the HTML. Now you write me the code to scrape all of this." And let's have it run. Again, notice that I am asking explicitly for code. I'm not saying, "Here is HTML, you convert it to some structured form." I do not trust LLMs to go through long pieces of text and get all of the information. I'm going to copy this code instead and put it out here. And it's copied something. Let's check. Paste it here. And yeah, somebody said, "Maybe after the first keynote, Rukmini S. and three other people outside of congratulated me on your talk, blah blah blah." No, it was a great talk.

[08:22](https://youtu.be/hPH5_ulHtno?t=08m22s) So, what you can do is now just keep scrolling up, scrolling up, scrolling up all the way to the top, which is what I was doing during the lunch break, and then get all the messages, which is what I have out here. We have all the messages starting from 2025 Jan 16th, when Zainab added Poojil, that's the first message that I have, and there were probably a few messages before that. All the way down to (I'll take out the connector and put it back. And this thing. Oh, it's back. Oh, thank you) 27th at 6 o'clock, which is what 11:30 AM. So yeah, probably pre-lunch.

[09:15](https://youtu.be/hPH5_ulHtno?t=09m15s) Now, we have these messages. But is everything all right? Just take a cursory look at this. Everything seems okay. But let's have the LLM do what I would normally do, which is figure out if the data is okay. So, let's go back and say, "Look, here are a bunch of WhatsApp messages. Are any of these, are there any missing values, for instance?" Let's start a new chat. And I like starting new chats because sometimes it gets confused. So, let's add the... I just G-zipped this file. Let's talk again. "Here are a bunch of WhatsApp messages. Are there any missing values here?"

[09:53](https://youtu.be/hPH5_ulHtno?t=09m53s) Let it figure it out. You'll notice that the model here is O4 Mini High. Now, O3 is the most advanced model. O4 Mini is a toned-down version of an even more advanced model. In practice, you can think of O4 Mini as a slightly lower model than O3, but when O4 fully releases, it will become the better model. High versus Normal means how much time it will spend thinking. Generally, the longer it thinks, for most problems where thinking helps, it does better. And programming is one of those kinds of tasks.

[10:29](https://youtu.be/hPH5_ulHtno?t=10m29s) So now, notice what it's doing is I said, "Are there any missing values?" It is smart enough to write a program. It didn't sit and read the data. It wrote a program to figure out the missing values. I can inspect it and see if it does a good job, and it usually does. And based on this, it's given me some missing value summary. I don't read tables or charts anymore. Just give it to me in plain English. And with the exclamation mark. Exclamation marks are nice.

[11:00](https://youtu.be/hPH5_ulHtno?t=11m00s) So, it's now thinking a lot and it says, "Only one author phone value is missing out of 1300 messages. And every other field, blah blah blah, is fully populated." It ran a missing value audit. "Wait, hold on. Is time also fully present? I thought I saw a missing time value." And this is where I'm just putting in some amount of context, or external information. This is really where the bulk of the value that humans will add going forward will come in from, where you present a different angle.

[11:37](https://youtu.be/hPH5_ulHtno?t=11m37s) Okay. "Time is blank on 65, about 5%. You still need to interpolate or impute for those time stamps." So, let's do that. What we'll do is tell it that, and I've got a prompt here that I was using from before, "Interpolate or extrapolate the time from the nearby messages. And give it to me finally as a G-zipped JSON file to download." It's transcribing and will execute.

[12:05](https://youtu.be/hPH5_ulHtno?t=12m05s) Now, part of the, normally I would have ad-libbed these prompts. The reason why I've put these prompts here is mostly because it's easier for me to publish online, and the QR code on all the slides will give you the links to this, so you'll be able to reproduce it. But what I also did was try running the same prompt three or four different ways to see if I run it multiple times, does it generally give the same consistent result, because, yes, I could come here and make a mess of things and still show you something interesting, but it's useful to have a system that gives reasonably reliable results.

[12:42](https://youtu.be/hPH5_ulHtno?t=12m42s) Now, one thing you'll notice here is that the analysis errored out midway. It wrote the code, it found that there was an error, but it then fixed the error by writing a new version of the code, and that's where the thinking part comes in. And that failed as well, then it wrote a third program. The more, the bigger or smarter the model, the more it does this sort of thing. And now I can download the WhatsApp messages with filled times, and that gives me another G-zipped JSON file. Good. So, what this does is helps me delegate even more. When I think, "Should I be cleaning?" ask it. "Are there any missing values?" ask it. "What should I be doing next?" ask it. **Every stage can be delegated**. It may do a good job, it may not do a good job, it will probably do a better job tomorrow. We'll figure it out.

[13:33](https://youtu.be/hPH5_ulHtno?t=13m33s) One of the common things that we want to do when it comes to unstructured data is to figure out, who's going to sit and read all of these? We'll group it into categories and for that I'd like to automate it. Now the way I normally automate this sort of thing is by creating topics, effectively a network cluster, saying these are the similar topics. For each of those clusters, let's give it a name of some kind and so on. So what I'll do is show you an interface by which we can do that, and then how we can build an application that can do that as well.

[14:04](https://youtu.be/hPH5_ulHtno?t=14m04s) So let me start by asking ChatGPT to give me a CSV download of all the text in the messages. That should hopefully do the trick. It will give me the CSV file. And then what I'm going to do is put that into an application that I built. What this application lets me do is paste all the text and then start clustering it. Has it already done this? Yes, it seems to. I will then open this CSV file. Let's just open it in VS Code or something. It should be in my downloads folder as messages.txt. Oh, it's got new lines and all that. No, I don't quite like this format. Let me take the JSON itself and take the text that appeared here and take everything except the comma at the end. I'm going to put all of this one line per row.

(Laughter)

[15:05](https://youtu.be/hPH5_ulHtno?t=15m05s) And why was that funny? But let's cluster it. Now what it will do is, and here is one of those secret, less known features of LLMs. You can quantifiably figure out how similar a piece of text is to another and say, "Okay, I want stuff that is 100% similar, 90% similar, 80% similar, 20% similar," whatever. Which is obviously powerful. So there seems to be a big cluster of messages which have similar text. Different people have requested to join, to review. Here's a cluster that says Gurman Bhatia. Where are you, Gurman? But these all seem to be about changing the group settings or removing someone from the community, or basic admin activity, and so on. So it looks like I'm already discovering a few topics. People wanting to join, Gurman administrating the group, and stuff like that.

[15:56](https://youtu.be/hPH5_ulHtno?t=15m56s) But I don't want to sit and manually do this. Let's delegate that as well. What we will do is say, "Look, you," and here I've written a program, which I will show you how to write in a few minutes, where I'll say, "Give me say a dozen topics and put it," send it to an LLM like, let's say, GPT 4.1 Mini, "And you find the topics." So, it's going to take all of these, find out which are similar using clustering, and then, having found the clusters, it's going to figure out what is the best name for these. So there are 97 documents about ticket sale pricing, 125 documents about spam and social links, 95 about promotions, blah blah blah, a dozen topics. And then I can download it, tag each of these messages against it.

[16:35](https://youtu.be/hPH5_ulHtno?t=16m35s) Now you'll say, "Anand, very good, you got this program. Can I use this program?" No, unfortunately not. Okay. How can you do this? What is the big deal about programs? LLMs write code. Write the code. So, what is the prompt that will get you to do this? And the answer is, write this out. So, this one I wrote using Claude Code. Claude Code is slightly different in that instead of running on the browser, it runs on the command line and is also somewhat expensive, but this one cost me about little less than a dollar. What I prompted it was literally what you see here. "I've got this JSON.gzip file. Now I want you to write a Python program, call it topics.py. What it should do is calculate the embeddings of each of the text fields. Cluster them using K-Means and then send it to GPT 4.1 to give me names for all of those. Create a new JSON file that adds a cluster to each of these messages. And test it on 20 messages with three clusters. And then if that works, run for all."

[17:36](https://youtu.be/hPH5_ulHtno?t=17m36s) So, this, it spent, so here's what the process looked like. What I just read out is what I typed. And then it said, "Okay, I'll create a topics.py." It created a plan and step by step it went through the plan. It wrote the code. It created this topics.py here. And then it said, "Okay, now I've created it, I've done all of these things. Now I'm going to test it." It ran the test. The test ran fine, blah blah blah. And finally it finished. It costing me about 20 cents in 2 minutes of its execution time and 4 minutes of me going out for a small cup of coffee. This is the third iteration that I ran of this prompt, not the first iteration, because I wanted to give you a prompt that works at the first shot. The first couple of times, I literally, let me run this program. `uv run topics.py`.

[18:24](https://youtu.be/hPH5_ulHtno?t=18m24s) So, it is now literally running. It's loading the thousand odd messages and processing it batch by batch, and it will eventually get done. But the reason this was the third attempt was because on my first attempt, I didn't put in a few of these things that I later on realized I needed to. So, I decided I'll combine them all into one single message to give it to you as an easy way. But my first iteration took about 22 minutes. I was at Brigade Road eating paneer kurchan tacos, which I will strongly recommend. And it, yeah, over 22 minutes, cost me less than a dollar. That is a solid bargain for you to be able to create a program that does end-to-end topic modeling.

[19:03](https://youtu.be/hPH5_ulHtno?t=19m03s) Now, now that we have something like this, which is, and it's created a cluster distribution, and strangely, the names of the clusters seem to be cluster seven, cluster eight, blah blah blah. Okay, it obviously did a terrible job of that. So, like always, I'm just going to rerun it and hopefully it will give me better cluster names. Normally it gives good cluster names, but like with LLMs, like with everything on LLMs, sometimes it does it right, sometimes it doesn't. The magic rule is **try it again**. Costs nothing. I'm anyway going to occupy my time speaking with you and if people like you are not around to occupy my time, I play a Bubbles game on MSN, which is very addictive.

[19:48](https://youtu.be/hPH5_ulHtno?t=19m48s) But now, it's processed batch 12. Now it's clustering into 12 clusters. Hopefully it will give better cluster names this time. And yeah, it's saying, "Group engagement, 82 messages, social media updates, blah blah blah." Now I have these messages.

[20:02](https://youtu.be/hPH5_ulHtno?t=20m02s) Next. Okay, yeah, sorry, before that. To reiterate, the **main takeaway here is if it doesn't work, throw it away, redo it**. You could try and fix it, that sometimes works, but throwing it away and redoing it is good enough a tactic. And after three times it doesn't work, this is an important thing: **write it down in a list saying I tried this, this is currently impossible**. One month later, revisit. That impossibility list is one of your **most useful tactics** in dealing with the ever-changing world of LLMs, because when a new model releases, you're going to ask, "What is the big deal?" If you have an impossibility list and you're able to strike off two of those, then you'll know what the big deal is about that model.

[20:42](https://youtu.be/hPH5_ulHtno?t=20m42s) Now let's visualize. So what I'm going to do is go back to ChatGPT. Which I suddenly can't find. Ah, no, this is not ChatGPT. This is. So let's create a new chat. And in this, I will upload the new file. I'm going to G-zip it because the network is not too good here. Tagged JSON G-zip. Now I'm going to add a photo or a file. Take this and yeah, let's tell it. "These are messages from the VizChitra group. What are interesting insights that we can derive from these? Give me **10 diverse data stories** that we can explore. Include some **quirky ones** as well. Then, for each of those, **write the code to analyze the data**. Show the results as tables and charts and **interpret each as a story with surprise and human appeal**. **Amuse me**!"

[21:41](https://youtu.be/hPH5_ulHtno?t=21m41s) Now, the quirky, amuse and all of that, I wouldn't do in a more serious setting. Or actually maybe I would. But it actually helps because even the very serious people tend to like this sort of thing. Now, I'm going to consciously switch over to O3. I don't have that large a quota of O3 and I have a workshop tomorrow, so I'm trying to conserve it. But by default, your operating principle should be, at least if you're on the $20 ChatGPT version, **always use O3 until you exhaust it**, and then go to the next lower models. I think you have about 200 per week. You're very unlikely to exhaust it.

[22:15](https://youtu.be/hPH5_ulHtno?t=22m15s) Now, one of the things that I'll mention here is **I am asking for 10 stories, not one**. Why would you ask for one? It's practically the same effort. **Never ask for just one output from an LLM. Have it give a dozen**. And if it is saying, "Oh, that's too much, I'll only give you two or three," fine. Also, you'll notice that I didn't say, "Do this analysis, do that analysis." I used. I used to say, "Okay, here are my hypotheses." And then I realized, "Hold on, I have two problems." One, hypothesis generation could be biased. I'm effectively applying my biases onto it. Now, some people call biases domain expertise, which is a valid point. But you want to do that? That's absolutely fine too. But these things anyway think differently. So, may as well have it come up with the hypothesis. So, not a good idea. Secondly, it is work. I don't like work. I like playing Bubbles. So, have it do the work. The whole point is more delegation. Let us delegate. And then while we are at it, why should all the entertainment go to Netflix and books and so on? I stopped reading books this year. This is far more entertainment. So, let it entertain us.

[23:27](https://youtu.be/hPH5_ulHtno?t=23m27s) What it's doing right now is thinking, calculating, it's working on Monologue Masters, longest consecutive runs. This thinking stuff is brilliant. It's enough entertainment. It's also a learning opportunity. You can see how it writes the code, how it regex stuff. A few days ago, I asked it to pull data from the Indian High Courts and analyze it. What I didn't realize was that I had given it the wrong AWS region. So, it tried pulling and it failed. And finally, it gave me an answer. It's only when I went through the thinking traces that I realized somewhere it said, "I am not able to pull the data, so let me make it up." So, okay, it happens.

[24:17](https://youtu.be/hPH5_ulHtno?t=24m17s) Now, it's still writing the code and this is one of the pleasures, pains of using a sophisticated model like O3, which will happily think for a long, long time. But at the end of it, notice that it's creating charts and it's probably got the stories below. So yeah. Okay. Gurman's had the maximum number of messages. Where is the chart? Okay, slow network. Followed by Amit, followed by Surbhi, Ipsa, Oojal. Congratulations, all of you. All the hard work that you've put in is really showing. But let's see what stories it's coming up with. Those are the fun ones to read.

[24:58](https://youtu.be/hPH5_ulHtno?t=24m58s) **Loudest voices**: the five people that write half the chat. Gurman shouts the loudest. Tuesday, 11 AM is rush hour. Sunday morning is a ghost town. And the love icon is the group's reserve currency, whereas the thumbs up inflates fast. I'm not sure what that means. Okay. So, 80-20 participation. Gurman, Amit, Surbhi, Ipsa, and Oojal are dominating. There's a weekday clustering and midnight spikes on hack days. All right. Reaction, oh okay. So, 35% of all the reactions were the love emoji, whereas the thumbs up was 26% and then there was a, yeah, the rest of it. Friday planning frenzy subsides as deliverables hit. Con strategy climbs post chat. Gurman's the de facto curator. Okay. Most stages point to him. Interesting about the gender miss there. Notice self-loops. Surbhi quoting Surbhi. Amit's seven message soliloquy beats Gurman's six. Que the cricket chirps soundtrack.

[26:09](https://youtu.be/hPH5_ulHtno?t=26m09s) You know, actually this is fun, but let me say, wait, didn't I, okay, yeah, okay. Let's, let's do this. I'm going to say, "**More metrics, more quirky**." And go on. It can go crazy. You can, you can drive it crazy one way or the other. But the thing is there is practically no limit. No, I take that back. Our **imagination is the limit**. And what I'm beginning to realize is all of the weird stuff that I see posted on the internet about what people are doing with LLMs and I say, "Why the hell are these people doing this?" is the fodder for what can be done. And these days most of, these days I'm trying hard to practice stretching my imagination.

[27:00](https://youtu.be/hPH5_ulHtno?t=27m00s) The takeaways from here, I'll repeat: **Ask LLMs to write the code**. Don't have it analyze, have it write the code to analyze. Don't ask for one, ask for a dozen pieces of analysis. Keep your **impossibility list**. Whatever doesn't work this time, works later. I will be sharing this list of more quirky messages in this, and you can scan the QR code. If you have any things that you'd like to try out, then you can take the same, probably shouldn't be sharing the data set, so I won't. But you can try the same on any WhatsApp group or anything else that you like and please share yours publicly. But remember, LLMs can help in **every step of the data to story value chain**: engineering, analysis, visualization. Try it. See where it fails. See where it works. Keep a log. And see if you can actually design data through dialogue. Best of luck.

(Applause)

**Moderator:** We have time for one question. Does anyone want to ask anything? Not about the chat group, anything else.

**Samarth:** Have you used this in an actual client project?

**Answer:** Have I used this in an an actual client project? Every time. Is there any other way to do it?

(Laughter)

**Question:** Maybe a half a question more. Anyone else? I see a hand there. Yes, please. What's the latest proof of failure of LLMs that you have?

**Answer:** Yesterday, Gurman (who could please raise her hand? I can't find you. Oh, thank you.) said, "What does it take to create...?" We were chatting about style guides, and it struck me that I'd love to create a style guide based on the Economist. You saw the charts, and the charts where as Karthik put it, just crappy standard Matplotlib stuff. So, I said, "Create. Take all the charts from the Economist. (I didn't give it the charts, you search for the charts from the Economist). You write the style guide. And then you rewrite it in a form that is suitable for Matplotlib. And then you create the charts using Matplotlib and show it to me." It wrote the style guide kind of okay, even for Matplotlib, but when it applied it, it was rubbish. So, that's the most recent addition. It can't write, it can't apply style guides and create visualizations well, as of today.

**Question:** Anand, a question from the live stream. Someone's asking, "Can this or has this been applied to speech analytics yet?"

**Answer:** Absolutely. I'll show you an example whenever. Just ping me. Not just speech from a transcribed speech to text, but also emotion detection. Hume.AI, I'm not sure I'm pronouncing it right, but it's spelled H-U-M-E, offers an API that extracts emotion. Gemini probably has the best transcription models, and with either of these, you can do some fantastic work with speech.

**Question:** What if you had the style in a separate file, and the code in a separate file? LLMs struggle. If you put it in line, it helps. Are there such techniques we can use?

**Answer:** Not required anymore because most of the code coding agents know enough to pick up from separate files, have large enough context window. Temporarily, such techniques help. As models and application techniques improve, they become less important. For example, one of the classic prompt engineering tricks was emotion prompting. Blackmail the LLM. "I will kill you if you don't..." or, "My life is at stake if you do this. If you don't do this, then I will lose my job." And all of that, and it tended to produce better results on some models. Over time that vanished. Today that is not required and in fact, some of the newer models, it degrades the performance a little bit. So the general rule of thumb is **do as little as possible**. The models will catch up. Everything else that you do, not everything, the vast majority of the things that we do are temporary.

**Moderator:** Thank you, Anand.

**Anand:** Okay, yeah. I got the hint. Thank you.

(Applause)
